# GPT2-Text-Generation
Task 1 - GPT-2 Text Generation | Prodigy Infotech Internship
# Task 1 - GPT-2 Text Generation

This project is part of my Generative AI Internship at **Prodigy Infotech**.

## ğŸ” Objective
To generate coherent and contextually relevant text using the GPT-2 language model from Hugging Face's `transformers` library.

## ğŸ’¡ What I Did
- Used Google Colab to run GPT-2
- Installed and loaded the model with Hugging Face's `pipeline`
- Gave a prompt: `"Once upon a time, there was a girl named Shreya"` ğŸ˜„
- Generated AI-written text based on that

## ğŸ§  Skills Gained
- Basics of Transformer models (GPT-2)
- Text generation using Hugging Face
- Working in Python and Google Colab
- Uploading projects to GitHub

## ğŸ“ Code
You can view the notebook file above or run it in Google Colab.

âœ… Task Completed as part of:  
Generative AI Internship â€“ Prodigy Infotech

